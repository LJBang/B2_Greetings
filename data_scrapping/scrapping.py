# -*- coding: utf-8 -*-
"""scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rkEN0aRpmcmSKokcHkT4UyiA8-UEIQLo
"""

import requests
from bs4 import BeautifulSoup
import numpy as np
import pandas as pd
import time

errorurl = {}  ##오류 나는 경우 저장
df = pd.DataFrame(columns = ['label','class0 id','class0 name','class1 id','class1 name','keyword','sentence']) ##데이터프레임 만들기

cls0dic = {'계절인사':0}  ##대분류 코드 / 계절인사 데이터가 이미 존재하므로 미리 넣고 1부터 시작
cls0 = 1

cls1dic = {} ##소분류 코드 
cls1 = 0
npage = 50
for page in range(1,npage+1):
    time.sleep(np.random.rand()*10) ##0~10초 랜덤으로 sleep, 매크로 방지에 도움이 될까 싶어 추가해봄.
    print('{0}/{1} pages start'.format(page, npage))
    url = 'https://bizmail.yesform.com/list/list.php?page='+str(page)+'&scale=5&sort=date&div=A11B11&mode=list'
    hdr = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.82 Safari/537.36'}
    response = requests.get(url=url, headers=hdr)
    if response.status_code!=200:  ##get에서 정상적인 응답이 오지 않은 경우 저장 후 break
        print(url)
        errorurl[url] = 'get error'
        break
    else:
        soup = BeautifulSoup(response.content.decode('euc-kr','replace'), 'html.parser')
        if page==1:  ##첫페이지인 경우 대분류 체크
            title = soup.find('title').get_text()
            a0, a1 = title.find('::'), title.find('#')
            cls0name = title[a0+3:a1-1]
            if not cls0name in cls0dic.keys():
                cls0dic[cls0name] = cls0
                cls0id = cls0
                cls0 += 1
            else:
                cls0id = cls0dic[cls0name]
        
        panels = soup.find_all('div', {'class': "panel-body"})
        keywords = soup.find_all('h4', {'class':"panel-title pull-left"})
        if len(panels)==len(keywords):
            for i, panel in enumerate(panels):
                keyword = keywords[i].get_text()
                a1 = keyword.find(')')
                cls1name = keyword[1:a1]
                keyword = keyword[a1+2:]
                if cls1name in cls1dic:
                    cls1id = cls1dic[cls1name]
                else:
                    cls1id = cls1
                    cls1dic[cls1name] = cls1id
                    cls1 += 1
                sentence = panel.get_text()
                sentence = sentence.strip()
                data = {'label':0,'class0 id':cls0id,'class0 name':cls0name,'class1 id':cls1id,'class1 name':cls1name,'keyword':keyword,'sentence':sentence}
                df = df.append(data, ignore_index=True)
        else:
            errorurl[url] = 'parsing error'
    print('success')

cls0name = cls0name.replace(' ','_')
df.to_csv('/content/drive/MyDrive/colab_data/{0}.csv'.format(cls0name))